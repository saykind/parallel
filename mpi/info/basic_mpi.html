<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=koi8-r">
<title>БАЗОВЫЕ ФУНКЦИИ MPI</title>
</head>

<body>

<h3>MPI. Терминология и обозначения</h3>

<p><em>MPI - message passing interface</em> - библиотека функций и набор средств, предназначенных
для разработки и выполнения параллельных программ, основанных на процессах, 
взаимодействующих с помощью  передачи сообщений.

</p><p>Каждому процессу присваивается <em>номер процесса</em> - целое неотрицательное число,
являющееся уникальным атрибутом каждого процесса. 
<p>
Процессы объединяются в <em>группы</em>, группы могут быть вложенными. С каждой группой ассоциирован свой
<strong>коммуникатор</strong>. Внутри
группы все процессы перенумерованы. Если коммуникатор объединяет <em>n</em> процессов, то их номерами будут целые числа от <em>0</em> до <em>n-1</em> включительно.  При передаче сообщений следует указать
идентификатор группы (<em>коммуникатор</em>), внутри которой производится пересылка, и номер процесса внутри этой группы. Изначально все процессы
содержатся в группе с предопределенным идентификатором <em>MPI_COMM_WORLD</em>.
</p></p><hr>
Далее, при описании процедур MPI, используется не входящее в синтаксис языка программирования ключевое слово OUT. 
Аргумент процедурного вызова предваряется ключевым словом OUT, если вызов может изменять этот аргумент.
<hr>
<a name="p2"></a>
<h3>Общие процедуры MPI</h3>

<p><strong>int MPI_Init( int* argc, char*** argv)</strong>
</p>
<p>Эта процедура должна быть вызвана в каждом процессе один и только один раз, причем прежде, чем будет вызвана какая-либо другая MPI-подпрограмма. 
Единственное исключение из этого правила - функция <em>MPI_Initialized</em>, с помощью которой можжно определить, была ли уже вызвана функция <em>MPI_Init</em>. 

</p><p>Возвращает: в случае успешного выполнения - <em>MPI_SUCCESS</em>, иначе
- код ошибки. (То же самое возвращают и все остальные рассматриваемые
ниже функции) 
</p>
<hr>
</p>


<p><strong>int MPI_Finalize( void )</strong> 
</p>
<p><em>MPI_Finalize</em> очищает все состояния MPI. Никакая другая MPI-процедура (даже <em>MPI_Init</em>)
не может быть вызвана после выполнения этой процедуры. Пользователь обязан гарантировать, что все незаконченные обмены будут 
завершены прежде, чем будет вызвана <em>MPI_Finalize</em>.
Сложный тип аргументов <em>MPI_Init</em> предусмотрен для того, чтобы передавать
всем процессам аргументы <em>main</em>:</p>

<pre>int main(int argc, char** argv)
{
      MPI_Init(&amp;argc, &amp;argv);
          ...
      MPI_Finalize();
}
</pre>
<hr>
<p><strong>int MPI_Comm_size( MPI_Comm comm, int* size_of_group)</strong> 

</p><p>Определение общего числа параллельных процессов в группе <em>comm</em>.
</p><ul>
<li><em>comm</em> - идентификатор группы 
</li><li>OUT <em>*size_of_group</em> - размер группы 
</li></ul>

<hr>

<p><strong>int MPI_Comm_rank( MPI_Comm comm, int* rank)</strong> 

</p><p>Определение номера процесса в группе <em>comm</em>. Значение, возвращаемое
по адресу <em>rank</em>, лежит в диапазоне от 0 до <em>size_of_group-1</em>.

</p><ul>
<li><em>comm</em> - идентификатор группы 
</li><li>OUT <em>*rank</em> - номер вызывающего процесса в группе <em>comm</em> 
</li></ul>

<hr>

<p><strong>double MPI_Wtime(void)</strong></p>
<p>Возвращает астрономическое время в секундах (вещественное число),
прошедшее с некоторого момента в прошлом. Гарантируется, что этот момент
не будет изменен за время существования процесса. </p>
<PRE>{
  double starttime, endtime;
  starttime = MPI_Wtime();
  ... хронометрируемый участок ...
  endtime = MPI_Wtime();
 printf("Выполнение заняло %f секунд\n", endtime-starttime);
}</PRE>

<p><strong>double MPI_Wtick(void)</strong></p>  
<p>Возвращает разрешение таймера (минимально возможную длительность измеряемого временн<em>о</em>го интервала).</p>
<PRE>
  endtime-starttime >= MPI_Wtick()
</PRE>


</p><hr>
<a name="p3"></a>
<h3>Прием/передача сообщений между отдельными процессами</h3>
<h4>Прием/передача сообщений с блокировкой</h4>
</p>
<p>Рассматриваемые в данном разделе функции обеспечивают передачу данных между двумя процессами.
<p>Функция приёма данных <em>MPI_Recv</em> является блокирующей.</p>
<p>Функция передачи данных  <em>MPI_Send</em> может выступать и как блокирующая, и как не блокирующая.
В ряде случаев её вызов может завершаться раньше, чем данные будут переданы.
В любом случае, вызов процедуры посылки сообщения
не возвращает управления до тех пор, пока данные и атрибуты сообщения не будут сохранены в другом месте. После возврата управления из этой функции 
процесс-отправитель может обращаться к буферу посылки и перезаписывать его. Сообщение к этому моменту либо передано в буфер принимающего процесса, 
либо скопировано во временный системный буфер на стороне передающего процесса.</p>

Подчеркнём ещё раз, что вызов функции <em>MPI_Send</em> не всегда приводит к блокировке. Решение о том, будет, или нет 
буферизовано исходящее сообщение, принимает MРI. Если длина 
сообщения меньше некоторого фиксированного значения, оно может быть буферизовано. В таком случае операция посылки может завершиться 
<b>до того</b>, как будет запущен соответствующий прием. С другой стороны, сообщение может быть длинным или свободное буферное пространство 
может оказаться исчерпано. В этом случае вызов <em>MPI_Send</em> не будет завершен, пока данные не будут переданы процессу-получателю.</p>
<p>
Следовательно, функция передачи сообщения <em>MPI_Send</em> может завершиться вне зависимости от того, был ли осуществлен соответствующий вызов функции приёма сообщения <em>MPI_Recv</em>. 
Она может быть завершена до окончания, и даже до начала приема. </p>
<p><strong>int MPI_Send(void* buf, int count, MPI_Datatype datatype, int dest,
int msgtag, MPI_Comm comm) </strong>

</p><ul>
<li><em>buf</em> - адрес начала буфера содержащего передаваемые данные
</li><li><em>count</em> - число передаваемых элементов в буфере посылки (неотрицательное целое число)
</li><li><em>datatype</em> - тип каждого из элементов в буфере посылки
</li><li><em>dest</em> - номер процесса-получателя
</li><li><em>msgtag</em> - тэг сообщения (целое число)
</li><li><em>comm</em> - идентификатор группы (коммуникатор)
</li></ul>

<p>При передаче  указывается адрес первого элемента <em>buf</em> передаваемых данных, количество последовательно размещенных 
элементов <em>count</em> и их тип <em>datatype</em>. Длина сообщения задается числом элементов, а не числом байтов. 
Количество элементов <em>count</em> в сообщении 
может быть равно нулю, это означает, что область данных в сообщении пуста. Базисные типы данных в сообщении 
соответствуют базисным типам данных используемого языка программирования. Ниже приведён пример соответствия некоторых базовых типов
языков MPI и C:
<pre>
    MPI_CHAR (char)
    MPI_INT (int)
    MPI_FLOAT (float)
    MPI_DOUBLE (double)	
</pre>	
</p>
<p>В дополнение к описанию данных сообщение несёт информацию, которая используется, чтобы различать и выбирать сообщения. 
Эта информация состоит из фиксированного количества полей, которые в совокупности называются <em>атрибутами</em> сообщения 
(<em>message envelope</em>). Эти поля таковы: <em>source, destination, tag, communicator</em> 
(номер процесса-отправителя сообщения, номер процесса-получателя, тэг, коммуникатор).</p>
<p>
Целочисленный аргумент тэг (<em>tag</em>) используется, чтобы различать типы сообщений. Диапазон значений тэга 
находится в пределах 0,... UB или <em>MPI_ANY_TAG</em>, где верхнее значение UB зависит от реализации. MPI требует, чтобы UB было не менее, чем 32767.
В простейшем случае тэг сообщения можно полагать равным 1 для всех сообщений.
</p><p>
Аргумент <em>comm</em> описывает коммуникатор (<em>communicator</em>), который используется в операциях обмена.</p>
<p>
Коммуникатор описывает коммуникационный контекст операции. 
Сообщение всегда принимается внутри контекста, в котором оно было послано; сообщения, посланные в различных контекстах, 
не смешиваются. Коммуникатор также описывает ряд процессов, разделяющих этот коммуникационный контекст. Эта группа 
процессов (<em>process group</em>) упорядочена и каждому из процессов этой группы присвоен уникальный, в пределах группы, номер. 
Таким образом, диапазон значений для <em>dest</em> :  [0, ... , n-1], где n - число процессов в группе.</p> 
<p>
В MPI предопределен коммуникатор <em>MPI_COMM_WORLD</em>. Он обеспечивает обмен между всеми доступными после инициализации MPI процессами. 
Каждый из процессов имеет свой уникальный номер в группе <em>MPI_COMM_WORLD</em>.</p>
<hr>
<p><strong>int MPI_Recv(void* buf, int count, MPI_Datatype datatype, int source,
int msgtag, MPI_Comm comm, MPI_Status *status)</strong>

</p><ul>
<li>OUT *<em>buf</em> - начальный адрес буфера процесса-получателя
</li><li><em>count</em> - максимальное число элементов в принимаемом сообщении (целое)
</li><li><em>datatype</em> - тип данных принимаемого сообщения (дескриптор)
</li><li><em>source</em> - номер процесса-отправителя (целое)
</li><li><em>msgtag</em> - идентификатор принимаемого сообщения (целое)
</li><li><em>comm</em> - идентификатор группы (коммуникатор)
</li><li>OUT <em>status</em> - параметры принятого сообщения (статус)
</li></ul>

<p>Буфер получения состоит из накопителя для размещения последовательности элементов, 
тип которых указан в поле <em>datatype</em> и адресуемых, начиная с адреса <em>buf</em>. 
Длина получаемого сообщения должна быть равна или меньше длины буфера получения, в противном случае 
возникнет ошибка переполнения. Если сообщение меньше размера буфера получения, то в нем модифицируются 
только начальные ячейки, соответствующие длине сообщения.
</p>
<p>
Селекция сообщения операцией приема выполняется под управлением значений атрибутов сообщения. 
Прием сообщения осуществляется, если его атрибуты соответствуют значениям источника, тэга и коммуникатора, 
указанным в операции приема. Процесс-получатель может задавать значение <em>MPI_ANY_SOURCE</em> 
для отправителя и/или значение <em>MPI_ANY_TAG</em> для тэга, определяя тем самым, что любой отправитель 
и/или тэг разрешен.</p>
<p>
Однако, нельзя задать произвольное значение для <em>comm</em>. Следовательно, сообщение может быть 
принято, если оно адресовано данному получателю в рамках соответствующего коммуникатора.</p>
<p>
Тэг сообщения задается аргументом <em>tag</em> операции приема. Аргумент отправителя, 
если он отличен от <em>MPI_ANY_SOURCE</em>, задается как номер внутри группы процессов, связанной 
с тем же самым коммуникатором. Следовательно, диапазон 
значений для аргумента отправителя находится в пределах [0,..., n-1] или {<em>MPI_ANY_SOURCE</em>}, где 
n - количество процессов в этой группе.</p>
<p>
Отметим <b>асимметрию</b> между операциями посылки и приема. Операция приема допускает получение сообщения 
от произвольного отправителя, в то время как в операции передачи должны быть указаны конкретные получатель и тег.</p>
<p>
Допускается ситуация, когда номера источника и получателя совпадают, то есть процесс может посылать сообщение 
самому себе, однако это небезопасно для описанных выше блокирующих операций посылки и приема, поскольку может 
привести к дедлоку <A href="http://www.mpi-forum.org/docs/mpi-11-html/node34.html">(<em>http://www.mpi-forum.org/docs/mpi-11-html/node34.html</em>)</A></p>

<p><em>Дополнительная информация</em> о результатах посылки сообщения возвращается с помощью аргумента <em>status</em>. 
Под соответствующую переменную должно быть обязательно выделено <em>адресное пространство</em>, динамически (например, 
с помощью функции <em>malloc</em>) или иначе, с помощью описания переменной типа <em>MPI_Status</em>.

<hr></p>

<hr>
<p><strong>int MPI_Barrier(MPI_Comm comm)</strong></p>

<p>Функция барьерной синхронизации <em>MPI_Barrier</em> блокирует вызывающий процесс до тех пор, пока эта функция не будет вызвана во всех процессы группы.
В каждом процессе управление возвращается только после того, как все процессы в группе вызовут процедуру <em>MPI_Barrier</em>.</p>

<hr>

<B><p>Список источников по теме:</p></B>
<pre>
<A href="http://www.mpi-forum.org/docs/mpi-11-html/mpi-report.html">MPI-1.1 Documentation </A>
<A href="http://www.opennet.ru/docs/RUS/mpi-1/">Стандарт языка MPI-1.1</A>
<A href="http://ilya-evseev.narod.ru/articles/mpi/index.html">MPI для начинающих: Евсеев И.</A>
<A href="http://parallel.ru/tech/tech_dev/MPI/">Учебное пособие по MPI: Антонов А.С. </A>
<A href="http://hpcu.ru/courses/23">Основы параллельного программирования с использованием MPI: Немнюгин С.А.</A>
</pre>

</body>

</html>
